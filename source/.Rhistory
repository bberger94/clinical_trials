#########################################################################
## parse_json.R ; Author: Ben Berger;                                  ##
## Modified from script by Andrew Marder:                              ##
## Original notes from AM:                                             ##
## I've written a function called `my_expand` to make working with the ##
## trials data a little bit easier. The `get_name`, `assert`, and      ##
## `json_to_dataframe` functions are helper functions that I used to   ##
## write the `my_expand` function.                                     ##
#########################################################################
library(dplyr)
library(rlang)
library(readr)
## Andrew: I prefer to assert conditions instead of stopping if not a condition.
assert <- stopifnot
get_name <- function(x) as.character(UQE(x))
## Apply json_to_dataframe to each cell of a column
my_expand <- function(df, id, var) {
id <- enquo(id)
var <- enquo(var)
varname <- deparse(substitute(var))
f <- function(row) {
assert(class(row) == "list")
if(varname == '~SitesByCountries') data <- json_to_dataframe_geodata(row[[get_name(var)]])
else data <- json_to_dataframe(row[[get_name(var)]], varname)
data[[get_name(id)]] <- row[[get_name(id)]]
return(data)
}
df %>%
select(!!id, !!var) %>%
filter(!is.na(!!var)) %>%
rowwise() %>%
do(f(.)) %>%
ungroup
}
## Parse a JSON cell as a tibble (data_frame)
json_to_dataframe <- function(s, varname) {
l <- jsonlite::fromJSON(s)
assert(class(l) == "list")
if(length(l) == 1) data <- l[[1]]
else data <- l
if (class(data) == "data.frame") {
return(data)
}
else {
data2 <- data.frame(data)
if(length(names(data)) == 0) names(data2) <- varname
else names(data2) <- names(data)
# next few lines are some test code for getting country data
# if(varname == '~SitesByCountries'){
#    data2$site_subdivision_code <- data2[['Sites.Site.CountrySubDivision']][['@code']]
#    data2$site_subdivision_name <- data2[['Sites.Site.CountrySubDivision']][['$']]
#    data2[['Sites.Site.CountrySubDivision']] <- NULL
# }
return(data2)
}
}
#Parse Geographic Data Column: Extract limited information
json_to_dataframe_geodata <- function(s) {
l <- jsonlite::fromJSON(s)
assert(class(l) == "list")
if(length(l) == 1) data <- l[[1]]
else data <- l
if(is.null(data[['@country']])) data[['@country']] <- NA
data <- data[['@country']] %>% as.data.frame
names(data) <- 'country'
return(data)
}
#########################################
## Call functions to parse JSON below  ##
#########################################
## Read in data
options(stringsAsFactors = FALSE)
#in.data <- read_csv('/Users/BBerger/Dropbox/Files_ClinTrials_Data/trials.csv')
in.data <- read_csv('../Dropbox/Files_ClinTrials_Data/trials.csv')
## Subset to test functions
set.seed(101)
sample_index <- sample(nrow(in.data), 1000)
trials <-
in.data %>%
slice(sample_index) %>%
rename(trial_id = id) %>%
arrange(trial_id)
setwd('../source/')
#########################################################################
## parse_json.R ; Author: Ben Berger;                                  ##
## Modified from script by Andrew Marder:                              ##
## Original notes from AM:                                             ##
## I've written a function called `my_expand` to make working with the ##
## trials data a little bit easier. The `get_name`, `assert`, and      ##
## `json_to_dataframe` functions are helper functions that I used to   ##
## write the `my_expand` function.                                     ##
#########################################################################
library(dplyr)
library(rlang)
library(readr)
## Andrew: I prefer to assert conditions instead of stopping if not a condition.
assert <- stopifnot
get_name <- function(x) as.character(UQE(x))
## Apply json_to_dataframe to each cell of a column
my_expand <- function(df, id, var) {
id <- enquo(id)
var <- enquo(var)
varname <- deparse(substitute(var))
f <- function(row) {
assert(class(row) == "list")
if(varname == '~SitesByCountries') data <- json_to_dataframe_geodata(row[[get_name(var)]])
else data <- json_to_dataframe(row[[get_name(var)]], varname)
data[[get_name(id)]] <- row[[get_name(id)]]
return(data)
}
df %>%
select(!!id, !!var) %>%
filter(!is.na(!!var)) %>%
rowwise() %>%
do(f(.)) %>%
ungroup
}
## Parse a JSON cell as a tibble (data_frame)
json_to_dataframe <- function(s, varname) {
l <- jsonlite::fromJSON(s)
assert(class(l) == "list")
if(length(l) == 1) data <- l[[1]]
else data <- l
if (class(data) == "data.frame") {
return(data)
}
else {
data2 <- data.frame(data)
if(length(names(data)) == 0) names(data2) <- varname
else names(data2) <- names(data)
# next few lines are some test code for getting country data
# if(varname == '~SitesByCountries'){
#    data2$site_subdivision_code <- data2[['Sites.Site.CountrySubDivision']][['@code']]
#    data2$site_subdivision_name <- data2[['Sites.Site.CountrySubDivision']][['$']]
#    data2[['Sites.Site.CountrySubDivision']] <- NULL
# }
return(data2)
}
}
#Parse Geographic Data Column: Extract limited information
json_to_dataframe_geodata <- function(s) {
l <- jsonlite::fromJSON(s)
assert(class(l) == "list")
if(length(l) == 1) data <- l[[1]]
else data <- l
if(is.null(data[['@country']])) data[['@country']] <- NA
data <- data[['@country']] %>% as.data.frame
names(data) <- 'country'
return(data)
}
#########################################
## Call functions to parse JSON below  ##
#########################################
## Read in data
options(stringsAsFactors = FALSE)
#in.data <- read_csv('/Users/BBerger/Dropbox/Files_ClinTrials_Data/trials.csv')
in.data <- read_csv('../Dropbox/Files_ClinTrials_Data/trials.csv')
## Subset to test functions
set.seed(101)
sample_index <- sample(nrow(in.data), 1000)
trials <-
in.data %>%
slice(sample_index) %>%
rename(trial_id = id) %>%
arrange(trial_id)
in.data <- read_csv('../trials.csv')
in.data <- read_csv('../data/trials.csv')
in.data <- read_csv('../../Files_ClinTrials_Data/trials.csv')
set.seed(101)
sample_index <- sample(nrow(in.data), 10000)
trials <-
in.data %>%
slice(sample_index) %>%
rename(trial_id = id) %>%
arrange(trial_id)
us_trials_long <-
trials %>%
#slice(166378) %>%
my_expand(trial_id, SitesByCountries) %>%
mutate(us_trial = (country == 'US')) %>%
ungroup %>% group_by(trial_id) %>%
summarize(us_trial = any(us_trial))
View(us_trials_long)
is.na(us_trials_long$us_trial)
is.na(us_trials_long$us_trial) %>% sumn
is.na(us_trials_long$us_trial) %>% sum
trials <-
in.data %>%
#slice(sample_index) %>%
rename(trial_id = id) %>%
arrange(trial_id)
us_trials_long <-
trials %>%
#slice(166378) %>%
my_expand(trial_id, SitesByCountries) %>%
mutate(us_trial = (country == 'US')) %>%
ungroup %>% group_by(trial_id) %>%
summarize(us_trial = any(us_trial))
is.na(us_trials_long$us_trial) %>% sum
table(us_trials_long$us_trial)
load('../data/clinical_trials_07-19-17.RData')
table(data$phase)
sum(is.na(data$phase1))
sum(is.na(data$phase_1))
sum(is.na(data$phase2))
sum(is.na(data$phase_2))
sum(is.na(data$phase_3))
sum(is.na(data %>% select(phase)))
sum(is.na(data %>% select(phase_1)))
data %>% select(phase_1) %>% is.na %>% sum()
data %>% select(phase_1) %>% filter(us_trial == 1) %>% is.na %>% sum
data %>% filter(us_trial == 1) %>% select(phase_1) %>% is.na %>% sum()
data %>% filter(us_trial == 1) %>% select(phase_1) %>% count
data %>% filter(us_trial == 1) %>% select(phase_1) %>% sum(is.na) / count
data %>% filter(us_trial == 1) %>% select(phase_1) %>% sum(is.na(.)) / count
data %>% filter(us_trial == 1) %>% select(phase_1) %>% is.na %>% sum/count
table(phase)
data %>% select(phase) %>% table
nrow(data)
data %>% select(phase) %>% table/nrow(.)
data %>% select(phase) %>% table/nrow(data)
data %>% select(phase) %>% table/nrow %>% sum
data %>% select(phase) %>% table/nrow
data %>% filter(us_trial == 1) %>% count
data %>% filter(us_trial == 1) %>% table(phase)
data %>% filter(us_trial == 1) %>% select(phase) %>% table
data %>% filter(us_trial == 1) %>% select(phase) %>% ftable
data %>% filter(us_trial == 1) %>% select(phase) %>% table
